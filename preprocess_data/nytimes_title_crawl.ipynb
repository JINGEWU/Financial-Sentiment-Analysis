{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "warming-butler",
   "metadata": {},
   "source": [
    "# Crawl headlines from nytimes webpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-utility",
   "metadata": {},
   "source": [
    "\n",
    " This programme can download data(i.e. news title) for the whole specific year from the nytimes news website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-demonstration",
   "metadata": {},
   "source": [
    " Change the code where says **# CHANGE HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "approximate-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import dateutil\n",
    "import datetime\n",
    "import configparser\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import urllib3\n",
    "from nytimesarticle import articleAPI\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ancient-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(start, end):\n",
    "    dates = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime('%Y %m').tolist()]\n",
    "#     print(dates)\n",
    "    months_in_range = []\n",
    "    for date in dates:\n",
    "        #print(date[1][0])\n",
    "        if date[1][0]=='0':\n",
    "            months_in_range.append([date[0],date[1].replace('0','')])\n",
    "        else:\n",
    "            months_in_range.append([date[0],date[1]])\n",
    "    return months_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "familiar-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2011-12-31\n",
      "End date: 2013-01-01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['2012', '1'],\n",
       " ['2012', '2'],\n",
       " ['2012', '3'],\n",
       " ['2012', '4'],\n",
       " ['2012', '5'],\n",
       " ['2012', '6'],\n",
       " ['2012', '7'],\n",
       " ['2012', '8'],\n",
       " ['2012', '9'],\n",
       " ['2012', '10'],\n",
       " ['2012', '11'],\n",
       " ['2012', '12'],\n",
       " ['2013', '1']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.disable();\n",
    "gc.enable();\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "YOUR_API_KEY= 'VCdDP0EMPdz3AUYHAkCQ12h6ELuTzJO8'\n",
    "\n",
    "# CHANGE HERE TO GET DATA OF THE YEAR YOU WANT\n",
    "end = datetime.date(2013, 1, 1) \n",
    "start = datetime.date(2011, 12, 31)\n",
    "print('Start date: ' + str(start))\n",
    "print('End date: ' + str(end))\n",
    "months_in_range=date_format(start,end)\n",
    "months_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-overall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prompt-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(date):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + YOUR_API_KEY\n",
    "    try:\n",
    "        response = requests.get(url, verify=False).json()\n",
    "    except Exception:\n",
    "        return None\n",
    "    time.sleep(6)\n",
    "    return response\n",
    "\n",
    "\n",
    "def is_valid(article, date):\n",
    "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
    "    is_in_range = date > start and date < end\n",
    "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
    "    return is_in_range and has_headline\n",
    "\n",
    "\n",
    "def parse_response(response):\n",
    "    '''Parses and returns response as pandas data frame.'''\n",
    "    data = {'headline': [],  \n",
    "        'date': [], \n",
    "#         'doc_type': [],\n",
    "#         'material_type': [],\n",
    "#         'section': [],\n",
    "        'keywords': []}\n",
    "    \n",
    "    articles = response['response']['docs'] \n",
    "    urls = []\n",
    "    dates_url = []\n",
    "#     title = []\n",
    "    for article in articles: # For each article, make sure it falls within our date range\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        if is_valid(article, date):\n",
    "            \n",
    "            data['headline'].append(article['headline']['main']) \n",
    "#             date = article['pub_date'].strftime(\"%Y%m%d\")\n",
    "#             dat = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %m\").tolist()]\n",
    "            time_stamp = pd.Timestamp(article['pub_date'])\n",
    "            dates_url.append(time_stamp.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "            data['date'].append(time_stamp.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#             if 'section' in article:\n",
    "#                 data['section'].append(article['section_name'])\n",
    "#             else:\n",
    "#                 data['section'].append(None)\n",
    "#             data['doc_type'].append(article['document_type'])\n",
    "#             if 'type_of_material' in article: \n",
    "#                 data['material_type'].append(article['type_of_material'])\n",
    "#             else:\n",
    "#                 data['material_type'].append(None)\n",
    "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
    "            data['keywords'].append(keywords)\n",
    "            urls.append(article[\"web_url\"])\n",
    "    print(\"Parse articles : \" , len(urls))\n",
    "    return urls,dates_url,data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indirect-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dates):\n",
    "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
    "    total = 0\n",
    "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
    "    if not os.path.exists('headlines'):\n",
    "        os.mkdir('headlines')\n",
    "    data_list = []\n",
    "    for date in dates:\n",
    "        print('Working on ' + str(date) + '...')\n",
    "#         csv_path = 'headlines/' + date[0] + '-' + date[1] + '.csv'\n",
    "        txt_path = \"nytimes_data/\"+ date[0] + '_' + date[1]\n",
    "#         if not os.path.exists(txt_path): # If we don't already have this month \n",
    "        response = send_request(date)\n",
    "#         if response is not None:\n",
    "        urls, date_all,data = parse_response(response)\n",
    "        data_list.append(data)\n",
    "#         print(data)\n",
    "        total += len(urls)\n",
    "#         counter = 0\n",
    "#         directory = \"nytimes_data/\"+date[0]+\"/\"+date[1]\n",
    "#         if not os.path.exists(directory):\n",
    "#             os.makedirs(directory)\n",
    "#         data = []\n",
    "#         for every_url in tqdm(urls):\n",
    "            \n",
    "# #             file = open(directory+\"/\"+ date_all[counter] + \"_\"+str(counter)+\".txt\",\"w\",encoding='utf-8') \n",
    "#             data.append(get_info(every_url))\n",
    "# #             file.write(data)\n",
    "# #             file.write(\"\\n\")\n",
    "# #             file.close()\n",
    "#             counter+=1\n",
    "#         print('Saving ' + txt_path + '...')\n",
    "# #         pprint(urls)\n",
    "#         data_list.append(data)\n",
    "                \n",
    "# #                 df.to_csv(csv_path, index=False)\n",
    "#     print(len(data_list))\n",
    "#     print('Number of articles collected: ' + str(total))\n",
    "    return urls,data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "engaged-effects",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: ['2012', '1'] to ['2013', '1']\n",
      "Working on ['2012', '1']...\n",
      "Parse articles :  9168\n",
      "Working on ['2012', '2']...\n",
      "Parse articles :  8796\n",
      "Working on ['2012', '3']...\n",
      "Parse articles :  9280\n",
      "Working on ['2012', '4']...\n",
      "Parse articles :  8240\n",
      "Working on ['2012', '5']...\n",
      "Parse articles :  8862\n",
      "Working on ['2012', '6']...\n",
      "Parse articles :  8704\n",
      "Working on ['2012', '7']...\n",
      "Parse articles :  7795\n",
      "Working on ['2012', '8']...\n",
      "Parse articles :  8202\n",
      "Working on ['2012', '9']...\n",
      "Parse articles :  8306\n",
      "Working on ['2012', '10']...\n",
      "Parse articles :  8731\n",
      "Working on ['2012', '11']...\n",
      "Parse articles :  7959\n",
      "Working on ['2012', '12']...\n",
      "Parse articles :  7212\n",
      "Working on ['2013', '1']...\n",
      "Parse articles :  0\n"
     ]
    }
   ],
   "source": [
    "url,data = get_data(months_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "following-hello",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Year Full of Missteps Is Finally Over</td>\n",
       "      <td>20120101-000028</td>\n",
       "      <td>[Athletics and Sports]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Serviceman Held for Carrying Explosives Into T...</td>\n",
       "      <td>20120101-000912</td>\n",
       "      <td>[Airport Security, AIRPORTS, Bombs and Explosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Picturing How Ryan Brothers Could Settle  Fami...</td>\n",
       "      <td>20120101-001459</td>\n",
       "      <td>[Football]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Experts Weigh In on Outside Groups’ Pro-Gingri...</td>\n",
       "      <td>20120101-001552</td>\n",
       "      <td>[Campaign Finance, Citizens United v Federal E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Unlikely Group Rebels Against Preservation ...</td>\n",
       "      <td>20120101-001554</td>\n",
       "      <td>[Historic Buildings and Sites, Restoration and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101250</th>\n",
       "      <td>How Many Slaves Work for You?</td>\n",
       "      <td>20121231-234532</td>\n",
       "      <td>[Human Trafficking, Emancipation Proclamation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101251</th>\n",
       "      <td>After Crispy Pig Ears, 10 Trends for 2013</td>\n",
       "      <td>20121231-234720</td>\n",
       "      <td>[Cooking and Cookbooks, Restaurants, Food]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101252</th>\n",
       "      <td>Hurting Knicks Uncertain of Tuesday’s Lineup</td>\n",
       "      <td>20121231-234851</td>\n",
       "      <td>[Basketball]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101253</th>\n",
       "      <td>Pursuing a First Win in the Bowls Since 1949</td>\n",
       "      <td>20121231-235117</td>\n",
       "      <td>[Football (College), Bowl Games]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101254</th>\n",
       "      <td>Bond Craze Could Run Its Course in New Year</td>\n",
       "      <td>20121231-235148</td>\n",
       "      <td>[United States Economy, Government Bonds, Muni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101255 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline             date  \\\n",
       "0                 A Year Full of Missteps Is Finally Over  20120101-000028   \n",
       "1       Serviceman Held for Carrying Explosives Into T...  20120101-000912   \n",
       "2       Picturing How Ryan Brothers Could Settle  Fami...  20120101-001459   \n",
       "3       Experts Weigh In on Outside Groups’ Pro-Gingri...  20120101-001552   \n",
       "4       An Unlikely Group Rebels Against Preservation ...  20120101-001554   \n",
       "...                                                   ...              ...   \n",
       "101250                      How Many Slaves Work for You?  20121231-234532   \n",
       "101251          After Crispy Pig Ears, 10 Trends for 2013  20121231-234720   \n",
       "101252       Hurting Knicks Uncertain of Tuesday’s Lineup  20121231-234851   \n",
       "101253       Pursuing a First Win in the Bowls Since 1949  20121231-235117   \n",
       "101254        Bond Craze Could Run Its Course in New Year  20121231-235148   \n",
       "\n",
       "                                                 keywords  \n",
       "0                                  [Athletics and Sports]  \n",
       "1       [Airport Security, AIRPORTS, Bombs and Explosi...  \n",
       "2                                              [Football]  \n",
       "3       [Campaign Finance, Citizens United v Federal E...  \n",
       "4       [Historic Buildings and Sites, Restoration and...  \n",
       "...                                                   ...  \n",
       "101250  [Human Trafficking, Emancipation Proclamation ...  \n",
       "101251         [Cooking and Cookbooks, Restaurants, Food]  \n",
       "101252                                       [Basketball]  \n",
       "101253                   [Football (College), Bowl Games]  \n",
       "101254  [United States Economy, Government Bonds, Muni...  \n",
       "\n",
       "[101255 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.DataFrame()\n",
    "for dat in data:\n",
    "    df_data = df_data.append(pd.DataFrame(dat),ignore_index=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-zambia",
   "metadata": {},
   "source": [
    "**we save data by year into .csv file**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-pound",
   "metadata": {},
   "source": [
    "Don't forget to change the path when saving data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "general-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved\n"
     ]
    }
   ],
   "source": [
    "# CHANGE HERE TO SAVE DATA IN YOUR LOCAL STORRAGE\n",
    "df_data.to_csv(path_or_buf=r'C:\\Users\\Dell\\Desktop\\data_with_title\\2012_title.csv')\n",
    "print('data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-retention",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-helping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
